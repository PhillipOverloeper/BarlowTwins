{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVvsSSV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+zfipP9bVwThzmKjq+/mS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhillipOverloeper/BarlowTwins/blob/main/SVvsSSV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WPBJVakyd25"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "\n",
        "from PIL import Image, ImageFilter, ImageOps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianBlur(object):\n",
        "  \"\"\"\n",
        "  Apply Gaussian blur with a certain probability p.\n",
        "  \"\"\"\n",
        "  def __init__(self, p):\n",
        "      self.p = p\n",
        "\n",
        "  def __call__(self, img):\n",
        "      if random.random() < self.p:\n",
        "          sigma = random.random() * 1.9 + 0.1\n",
        "          return img.filter(ImageFilter.GaussianBlur(sigma))\n",
        "      else:\n",
        "          return img\n",
        "\n",
        "      \n",
        "class Solarization(object):\n",
        "  \"\"\"\n",
        "  Apply solarization with a certain probability p.\n",
        "  \"\"\"\n",
        "  def __init__(self, p):\n",
        "      self.p = p\n",
        "\n",
        "  def __call__(self, img):\n",
        "      if random.random() < self.p:\n",
        "          return ImageOps.solarize(img)\n",
        "      else:\n",
        "          return img"
      ],
      "metadata": {
        "id": "o8sUWBPt-xQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Barlow_Transform:\n",
        "    def __init__(self, train=True, input_height=224):\n",
        "        self.train = train\n",
        "        # First augmented image \n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(input_height, interpolation=Image.BICUBIC),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "            GaussianBlur(p=1.0),\n",
        "            Solarization(p=0.0),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "        # Second augmented image\n",
        "        self.transform_prime = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(input_height, interpolation=Image.BICUBIC),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)], p=0.8),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "            GaussianBlur(p=0.1),\n",
        "            Solarization(p=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "    def __call__(self, x):\n",
        "        y1 = self.transform(x)\n",
        "        y2 = self.transform_prime(x)\n",
        "        if self.train == True:\n",
        "          return y1, y2\n",
        "        else:\n",
        "          return y1"
      ],
      "metadata": {
        "id": "43ne-3gW5g6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 4\n",
        "batch_size = 4\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Defining the augmentations for the supervised and self-supervised learning\n",
        "transforms_supervised = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "transforms_barlow_twins_train = Barlow_Transform(train=True, input_height = 32)\n",
        "transforms_barlow_twins_test = Barlow_Transform(train=False, input_height = 32)\n",
        "\n",
        "# Loading the test and train dataset for supervised learning\n",
        "trainset_supervised = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_supervised)\n",
        "trainloader_supervised = torch.utils.data.DataLoader(trainset_supervised, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testset_supervised = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_supervised)\n",
        "testloader_supervised = torch.utils.data.DataLoader(testset_supervised, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Loading the test and train dataset for self-supervised learning\n",
        "trainset_barlow_twins = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_barlow_twins_train)\n",
        "trainloader_barlow_twins = torch.utils.data.DataLoader(trainset_barlow_twins, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testset_barlow_twins = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_barlow_twins_test)\n",
        "testloader_barlow_twins = torch.utils.data.DataLoader(testset_barlow_twins, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ1pex1uyv_7",
        "outputId": "288170e8-5445-4baf-ddf8-be274587ed82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:892: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  \"\"\"\n",
        "  Model for the learning\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ax5RWdNY0bSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Barlow_Twins(nn.Module):\n",
        "  \"\"\"\n",
        "  Defining the Barlow Twins architecture\n",
        "  \"\"\"\n",
        "  def __init__(self, kerneltype='gauss', param=2):\n",
        "    super().__init__()\n",
        "    self.param = param\n",
        "    self.kerneltype = kerneltype\n",
        "\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    if self.kerneltype == 'gauss':\n",
        "      out = torch.exp(-torch.cdist(x1.T, x2.T, p=2)/self.param)\n",
        "      out = out + 0\n",
        "    elif self.kerneltype == 'poly':\n",
        "      x1_norm = x1 / torch.max(x1.norm(dim=1)[:, None], 1e-08 * torch.ones(x1.shape, device='cuda:0'))\n",
        "      x2_norm = x2 / torch.max(x2.norm(dim=1)[:, None], 1e-08 * torch.ones(x2.shape, device='cuda:0'))\n",
        "      out = torch.matmul(x1.T, x2).add_(1).pow_(self.param)\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "ukeyN8ISATlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Barlow_Twins_Loss(nn.Module):\n",
        "  def __init__(self, lambda_coeff=5e-3):\n",
        "    super().__init__()\n",
        "\n",
        "    self.lambda_coeff = lambda_coeff\n",
        "\n",
        "\n",
        "  def off_diagonal_elements(self, x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n-1, n+1)[:,1:].flatten()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    on_diag = torch.diagonal(x).add_(-1).pow_(2).sum()\n",
        "    off_diag = self.off_diagonal_elements(x).pow_(2).sum()\n",
        "\n",
        "    return on_diag + self.lambda_coeff * off_diag\n",
        "\n"
      ],
      "metadata": {
        "id": "ZPzP-21MDDdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_supervised = Net().to(device)\n",
        "net_barlow_twins = Net().to(device)\n",
        "criterion_supervised = nn.CrossEntropyLoss()\n",
        "criterion_barlow_twins = Barlow_Twins_Loss(5e-3)\n",
        "optimizer_supervised = optim.SGD(net_supervised.parameters(), lr=learning_rate, momentum=0.9)\n",
        "optimizer_barlow_twins = optim.SGD(net_barlow_twins.parameters(), lr=learning_rate, momentum=0.9)\n",
        "barlow_twins = Barlow_Twins('gauss', 2)"
      ],
      "metadata": {
        "id": "79tqNDrvJmdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def supervised_training():\n",
        "  for epoch in range(num_epochs):\n",
        "    for i,data in enumerate(trainloader_supervised):\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      optimizer_supervised.zero_grad()\n",
        "\n",
        "      outputs = net_supervised(inputs)\n",
        "      loss = criterion_supervised(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer_supervised.step()\n",
        "\n",
        "      if i % 2000 == 1999:\n",
        "        print('Epoch: ' + str(epoch) + ' Loss: ' + str(loss.item()))\n",
        "\n",
        "\n",
        "def self_supervised_training():\n",
        "  for epoch in range(num_epochs):\n",
        "    for i,data in enumerate(trainloader_barlow_twins):\n",
        "      (x1, x2), _ = data\n",
        "      x1 = x1.to(device)\n",
        "      x2 = x2.to(device)\n",
        "\n",
        "      optimizer_barlow_twins.zero_grad()\n",
        "\n",
        "      output1 = net_barlow_twins(x1)\n",
        "      output2 = net_barlow_twins(x2)\n",
        "      \n",
        "      result = barlow_twins(output1, output2)\n",
        "\n",
        "      loss = criterion_barlow_twins(result)\n",
        "      loss.backward()\n",
        "      optimizer_barlow_twins.step()\n",
        "\n",
        "      if i % 2000 == 1999:\n",
        "        print('Epoch: ' + str(epoch) + ' Loss: ' + str(loss.item()))"
      ],
      "metadata": {
        "id": "87PJCXlF1mSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_main():\n",
        "  supervised_training()\n",
        "  self_supervised_training()\n",
        "\n",
        "train_main()"
      ],
      "metadata": {
        "id": "SOykcZC5JpXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3791ea-ce44-47b0-9b74-c7275ea92b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss: 1.9389715194702148\n",
            "Epoch: 0 Loss: 1.8363032341003418\n",
            "Epoch: 0 Loss: 2.40303635597229\n",
            "Epoch: 0 Loss: 1.9403637647628784\n",
            "Epoch: 0 Loss: 1.1534676551818848\n",
            "Epoch: 0 Loss: 1.5989958047866821\n",
            "Epoch: 1 Loss: 1.5387200117111206\n",
            "Epoch: 1 Loss: 0.9371784925460815\n",
            "Epoch: 1 Loss: 1.3717752695083618\n",
            "Epoch: 1 Loss: 1.0787931680679321\n",
            "Epoch: 1 Loss: 0.7915328741073608\n",
            "Epoch: 1 Loss: 1.5494095087051392\n",
            "Epoch: 2 Loss: 1.6277580261230469\n",
            "Epoch: 2 Loss: 0.4478660225868225\n",
            "Epoch: 2 Loss: 1.9994100332260132\n",
            "Epoch: 2 Loss: 0.8134677410125732\n",
            "Epoch: 2 Loss: 1.8274331092834473\n",
            "Epoch: 2 Loss: 0.6423535943031311\n",
            "Epoch: 3 Loss: 1.7317004203796387\n",
            "Epoch: 3 Loss: 0.35873278975486755\n",
            "Epoch: 3 Loss: 1.535015344619751\n",
            "Epoch: 3 Loss: 1.4384207725524902\n",
            "Epoch: 3 Loss: 1.1131490468978882\n",
            "Epoch: 3 Loss: 1.221085786819458\n",
            "Epoch: 0 Loss: 0.02204468473792076\n",
            "Epoch: 0 Loss: 0.00498190987855196\n",
            "Epoch: 0 Loss: 0.004069502931088209\n",
            "Epoch: 0 Loss: 0.0011720256879925728\n",
            "Epoch: 0 Loss: 0.0008159783901646733\n",
            "Epoch: 0 Loss: 0.0007090838626027107\n",
            "Epoch: 1 Loss: 0.0004007741517852992\n",
            "Epoch: 1 Loss: 0.00028804325847886503\n",
            "Epoch: 1 Loss: 0.00023809249978512526\n",
            "Epoch: 1 Loss: 0.00021038424165453762\n",
            "Epoch: 1 Loss: 0.000279617786873132\n",
            "Epoch: 1 Loss: 0.00017059763194993138\n",
            "Epoch: 2 Loss: 0.0003722728288266808\n",
            "Epoch: 2 Loss: 0.00021464293240569532\n",
            "Epoch: 2 Loss: 0.0001397068554069847\n",
            "Epoch: 2 Loss: 9.49903842411004e-05\n",
            "Epoch: 2 Loss: 8.599868306191638e-05\n",
            "Epoch: 2 Loss: 0.00010874230792978778\n",
            "Epoch: 3 Loss: 7.315698894672096e-05\n",
            "Epoch: 3 Loss: 6.241355004021898e-05\n",
            "Epoch: 3 Loss: 6.216365000000224e-05\n",
            "Epoch: 3 Loss: 5.549523120862432e-05\n",
            "Epoch: 3 Loss: 6.442015728680417e-05\n",
            "Epoch: 3 Loss: 6.941379979252815e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def supervised_test():\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in testloader_supervised:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      outputs = net_supervised(images)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
        "\n",
        "\n",
        "def barlow_twins_test():\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in testloader_barlow_twins:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      outputs = net_barlow_twins(images)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "3IWt7g7NgX8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_main():\n",
        "  supervised_test()\n",
        "  barlow_twins_test()\n",
        "\n",
        "test_main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYg4g_cglL_d",
        "outputId": "7e35790d-3fd2-4c57-e058-492ad809d385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 58 %\n",
            "Accuracy of the network on the 10000 test images: 10 %\n"
          ]
        }
      ]
    }
  ]
}